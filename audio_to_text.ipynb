{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model to be used and name of the file and video source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import whisper\n",
    "# Define what model to use possible variations are\n",
    "# 'tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en' 'medium', 'large-v1', 'large-v2', 'large'\n",
    "# NOTE: Large models require more than 11GB VRAM\n",
    "model_name = \"medium\"\n",
    "audio_model = whisper.load_model(model_name)\n",
    "\n",
    "# Define url to download video and wanted filename\n",
    "\n",
    "name = 'SET YOUR OWN'\n",
    "\n",
    "url = 'SET YOUR OWN'\n",
    "\n",
    "mp4_file = name+\".mp4\"\n",
    "mp3_file = name+\".mp3\"\n",
    "txt_file = name+\".txt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get video from internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import m3u8_To_MP4\n",
    "# Download video\n",
    "if \".m3u8\" in url:\n",
    "    m3u8_To_MP4.multithread_download(url)\n",
    "    # Rename file\n",
    "    os.rename('m3u8_To_MP4.mp4', mp4_file)\n",
    "elif \".mp4\" in url:\n",
    "    urllib.request.urlretrieve(url, mp4_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to mp3 and filter noise and silent parts out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: install ffmpeg with choco to windows\n",
    "# ~5min for 1.5h file\n",
    "# Convert mp4 to mp3\n",
    "os.system('ffmpeg -i {} -vn -y {}'.format(mp4_file, mp3_file))\n",
    "print(\"mp4 to mp3 conversion done\")\n",
    "\n",
    "# Remove noise remove noise using FFT filering\n",
    "os.system(\"ffmpeg -i {} -af afftdn=nr=3 -y {}\".format(mp3_file, \"tmp_\" + mp3_file))\n",
    "print(\"Noise reduction done\")\n",
    "\n",
    "# Remove silent spots longer than 10s\n",
    "os.system(\"ffmpeg -i {} -af silenceremove=stop_periods=-1:stop_duration=10:stop_threshold=-50dB -y {}\".format(\"tmp_\" + mp3_file, mp3_file))\n",
    "print(\"Silent parts removed\")\n",
    "\n",
    "# Delete temporary file\n",
    "os.remove(\"tmp_\" + mp3_file)\n",
    "os.remove(mp4_file)\n",
    "print(\"Extra files removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = {\"en\": \"english\",\"zh\": \"chinese\",\"de\": \"german\",\"es\": \"spanish\",\"ru\": \"russian\",\"ko\": \"korean\",\"fr\": \"french\",\"ja\": \"japanese\",\"pt\": \"portuguese\",\"tr\": \"turkish\",\"pl\": \"polish\",\"ca\": \"catalan\",\"nl\": \"dutch\",\"ar\": \"arabic\",\"sv\": \"swedish\",\"it\": \"italian\",\"id\": \"indonesian\",\"hi\": \"hindi\",\"fi\": \"finnish\",\"vi\": \"vietnamese\",\"he\": \"hebrew\",\"uk\": \"ukrainian\",\"el\": \"greek\",\"ms\": \"malay\",\"cs\": \"czech\",\"ro\": \"romanian\",\"da\": \"danish\",\"hu\": \"hungarian\",\"ta\": \"tamil\",\"no\": \"norwegian\",\"th\": \"thai\",\"ur\": \"urdu\",\"hr\": \"croatian\",\"bg\": \"bulgarian\",\"lt\": \"lithuanian\",\"la\": \"latin\",\"mi\": \"maori\",\"ml\": \"malayalam\",\"cy\": \"welsh\",\"sk\": \"slovak\",\"te\": \"telugu\",\"fa\": \"persian\",\"lv\": \"latvian\",\"bn\": \"bengali\",\"sr\": \"serbian\",\"az\": \"azerbaijani\",\"sl\": \"slovenian\",\"kn\": \"kannada\",\"et\": \"estonian\",\"mk\": \"macedonian\",\"br\": \"breton\",\"eu\": \"basque\",\"is\": \"icelandic\",\"hy\": \"armenian\",\"ne\": \"nepali\",\"mn\": \"mongolian\",\"bs\": \"bosnian\",\"kk\": \"kazakh\",\"sq\": \"albanian\",\"sw\": \"swahili\",\"gl\": \"galician\",\"mr\": \"marathi\",\"pa\": \"punjabi\",\"si\": \"sinhala\",\"km\": \"khmer\",\"sn\": \"shona\",\"yo\": \"yoruba\",\"so\": \"somali\",\"af\": \"afrikaans\",\"oc\": \"occitan\",\"ka\": \"georgian\",\"be\": \"belarusian\",\"tg\": \"tajik\",\"sd\": \"sindhi\",\"gu\": \"gujarati\",\"am\": \"amharic\",\"yi\": \"yiddish\",\"lo\": \"lao\",\"uz\": \"uzbek\",\"fo\": \"faroese\",\"ht\": \"haitian creole\",\"ps\": \"pashto\",\"tk\": \"turkmen\",\"nn\": \"nynorsk\",\"mt\": \"maltese\",\"sa\": \"sanskrit\",\"lb\": \"luxembourgish\",\"my\": \"myanmar\",\"bo\": \"tibetan\",\"tl\": \"tagalog\",\"mg\": \"malagasy\",\"as\": \"assamese\",\"tt\": \"tatar\",\"haw\": \"hawaiian\",\"ln\": \"lingala\",\"ha\": \"hausa\",\"ba\": \"bashkir\",\"jw\": \"javanese\",\"su\": \"sundanese\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect language if english model not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \".en\" not in model_name:\n",
    "    # Detect language\n",
    "    audio = whisper.load_audio(mp3_file)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(audio_model.device)\n",
    "    _, probs = audio_model.detect_language(mel)\n",
    "    detected_language = LANGUAGES[max(probs, key=probs.get)]\n",
    "    print(f\"Detected language: {detected_language}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe audio takes about 9 min with gtx1070 to trancsribe 1.5h audio using medium.en\n",
    "\n",
    "if \".en\" not in model_name:\n",
    "    result = audio_model.transcribe(mp3_file, verbose= True, language=detected_language, temperature=0.8)\n",
    "else:\n",
    "    result = audio_model.transcribe(mp3_file, verbose= True, temperature=0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split each sentence to own row and delete .mp3-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(mp3_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(txt_file, 'w') as f:\n",
    "    # Write data to the file\n",
    "    f.write(result[\"text\"])\n",
    "    \n",
    "try:\n",
    "    # Open the file for reading\n",
    "    with open(txt_file, 'r') as file:\n",
    "        contents = file.read()\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a empty to be saved later\n",
    "    contents = ''\n",
    "\n",
    "# Split text where sentences end\n",
    "contents = contents.replace('\\n', '')\n",
    "contents = contents.replace('?', '?\\n')\n",
    "contents = contents.replace('.', '.\\n')\n",
    "contents = contents.replace('!', '!\\n')\n",
    "# Only use this if some sentences are really long.\n",
    "#contents = contents.replace(',', ',\\n')\n",
    "\n",
    "# Open the file for writing and overwrite the existing contents\n",
    "with open(txt_file, 'w') as file:\n",
    "    file.write(contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedd sentences and calulate cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sentences = []\n",
    "with open(txt_file, 'r') as file:\n",
    "        for line in file:\n",
    "                # Remove too short lines\n",
    "                if len(line)>6:\n",
    "                        sentences.append(line)\n",
    "\n",
    "# Define model to be used to be used for text embedding and create similarity matrix\n",
    "text_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = text_model.encode(sentences)\n",
    "similarities = cosine_similarity(embeddings)\n",
    "\n",
    "# Plot the similarity heatmap\n",
    "sns.heatmap(similarities).set_title('Cosine similarities matrix {}'.format(name))\n",
    "#plt.savefig('{}.png'.format(name), dpi=2000)\n",
    "\n",
    "# Get diagonal and the one next to it for sentence similarity checking\n",
    "diagonals = [similarities.diagonal(), similarities.diagonal(1)+similarities.diagonal(1)[-1]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get diagonals and detect where paragraphs should end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate differences\n",
    "difference = [diagonals[0][i]-diagonals[1][i] for i in range(len(diagonals[0])-1)]\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "# Perform n-wide Gaussian smoothing\n",
    "n = 1\n",
    "difference_smoothed = gaussian_filter1d(difference, n)\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Detect peaks where sentence difference is largest\n",
    "peaks, _ = find_peaks(difference_smoothed, distance=5)\n",
    "\n",
    "# Plot peaks\n",
    "plt.clf()\n",
    "plt.plot(difference_smoothed)\n",
    "plt.plot(peaks, difference_smoothed[peaks], \"x\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse final text file using detected paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format text for last step and remove too short sentences.\n",
    "with open(txt_file, 'r') as file:\n",
    "            contents = [l.rstrip(\"\\n\").lstrip() for l in file.readlines() if len(l)>6]\n",
    "\n",
    "# Add paragraph breaks to detected points and write to file\n",
    "text = ''\n",
    "for index, sentence in enumerate(contents):\n",
    "        if index-1 in peaks:\n",
    "                text += \"\\n\\n\"\n",
    "                text += sentence\n",
    "        else:\n",
    "                text += \" \"+sentence\n",
    "\n",
    "with open(txt_file, 'w') as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import OpenAI and define API_key\n",
    "###### You have to use your own api key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "with open(\"OPENAI_API_KEY\", 'r') as file:\n",
    "    API_key=(file.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting text into chunks so that OpenAi token limit is not exceeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_to_chunks(text):\n",
    "    max_len = 10000\n",
    "    split_points = []\n",
    "    curr_len = 0\n",
    "    for i, char in enumerate(text):\n",
    "        curr_len += 1\n",
    "        if curr_len >= max_len and (char == \".\" or char == \"!\" or char == \"?\"):\n",
    "            split_points.append(i+1)\n",
    "            curr_len = 0\n",
    "    if not split_points:\n",
    "        return [text]\n",
    "    else:\n",
    "        split_texts = []\n",
    "        prev_split = 0\n",
    "        for split in split_points:\n",
    "            split_texts.append(text[prev_split:split])\n",
    "            prev_split = split\n",
    "        split_texts.append(text[prev_split:])\n",
    "        return split_texts\n",
    "\n",
    "chunks = split_text_to_chunks(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use OpenAI api to get bulletpoints for each text chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = API_key\n",
    "bullet_points =  []\n",
    "\n",
    "for index, text in enumerate(chunks):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"You are a student whose job is to summarize following text in to bullet points in the original language. You can use your own knowledge also when making notes if you notice some inconsistencies or typos on the lecture text. Use your own words and do not just copy the lecture.\"},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "    )\n",
    "    bullet_points.append(response.choices[0].message.content)\n",
    "\n",
    "with open(\"Bullet_points_\"+name+\".txt\", 'w') as file:\n",
    "    file.write(' '.join(bullet_points))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40118f5f031a3101398604df892af6a231730f3865c9218da6290b373807c8b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
