{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model to be used and name of the file and video source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import whisper\n",
    "import tqdm\n",
    "import torch\n",
    "# Define what model to use possible variations are\n",
    "# 'tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en' 'medium', 'large-v1', 'large-v2', 'large'\n",
    "# NOTE: Large models require more than 11GB VRAM\n",
    "model_name = \"medium\"\n",
    "devices = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Cuda used: \",torch.cuda.is_available())\n",
    "audio_model = whisper.load_model(model_name, device=devices)\n",
    "\n",
    "# Define url to download video and wanted filename\n",
    "\n",
    "name = 'SET YOUR OWN'\n",
    "\n",
    "url = 'SET YOUR OWN'\n",
    "\n",
    "mp4_file = name+\".mp4\"\n",
    "mp3_file = name+\".mp3\"\n",
    "txt_file = name+\".txt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get video from internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import m3u8_To_MP4\n",
    "from pytube import YouTube\n",
    "\n",
    "# Download video\n",
    "if \".m3u8\" in url:\n",
    "    m3u8_To_MP4.multithread_download(url)\n",
    "    # Rename file\n",
    "    os.rename('m3u8_To_MP4.mp4', mp4_file)\n",
    "\n",
    "elif \".mp4\" in url:\n",
    "    urllib.request.urlretrieve(url, mp4_file)\n",
    "\n",
    "elif \"youtube\" in url:\n",
    "    yt = YouTube(url)\n",
    "    stream = yt.streams.get_by_itag(18)\n",
    "    stream.download(filename=mp4_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to mp3 and filter noise and silent parts out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: install ffmpeg with choco to windows\n",
    "# NOTE: install ffmpeg with brew on mac\n",
    "\n",
    "# Convert mp4 to mp3\n",
    "os.system(f'ffmpeg -i {mp4_file} -vn -y {mp3_file}')\n",
    "print(\"mp4 to mp3 conversion done\")\n",
    "\n",
    "# Remove noise remove noise using FFT filering\n",
    "os.system(f'ffmpeg -i {mp3_file} -af afftdn=nr=3 -y {\"tmp_\" + mp3_file}')\n",
    "print(\"Noise reduction done\")\n",
    "\n",
    "# Remove silent spots longer than 10s\n",
    "os.system(f'ffmpeg -i {\"tmp_\" + mp3_file} -af silenceremove=stop_periods=-1:stop_duration=10:stop_threshold=-50dB -y {mp3_file}')\n",
    "print(\"Silent parts removed\")\n",
    "\n",
    "# Delete temporary file\n",
    "os.remove(\"tmp_\" + mp3_file)\n",
    "os.remove(mp4_file)\n",
    "print(\"Extra files removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = {\"en\": \"english\",\"zh\": \"chinese\",\"de\": \"german\",\"es\": \"spanish\",\"ru\": \"russian\",\"ko\": \"korean\",\"fr\": \"french\",\"ja\": \"japanese\",\"pt\": \"portuguese\",\"tr\": \"turkish\",\"pl\": \"polish\",\"ca\": \"catalan\",\"nl\": \"dutch\",\"ar\": \"arabic\",\"sv\": \"swedish\",\"it\": \"italian\",\"id\": \"indonesian\",\"hi\": \"hindi\",\"fi\": \"finnish\",\"vi\": \"vietnamese\",\"he\": \"hebrew\",\"uk\": \"ukrainian\",\"el\": \"greek\",\"ms\": \"malay\",\"cs\": \"czech\",\"ro\": \"romanian\",\"da\": \"danish\",\"hu\": \"hungarian\",\"ta\": \"tamil\",\"no\": \"norwegian\",\"th\": \"thai\",\"ur\": \"urdu\",\"hr\": \"croatian\",\"bg\": \"bulgarian\",\"lt\": \"lithuanian\",\"la\": \"latin\",\"mi\": \"maori\",\"ml\": \"malayalam\",\"cy\": \"welsh\",\"sk\": \"slovak\",\"te\": \"telugu\",\"fa\": \"persian\",\"lv\": \"latvian\",\"bn\": \"bengali\",\"sr\": \"serbian\",\"az\": \"azerbaijani\",\"sl\": \"slovenian\",\"kn\": \"kannada\",\"et\": \"estonian\",\"mk\": \"macedonian\",\"br\": \"breton\",\"eu\": \"basque\",\"is\": \"icelandic\",\"hy\": \"armenian\",\"ne\": \"nepali\",\"mn\": \"mongolian\",\"bs\": \"bosnian\",\"kk\": \"kazakh\",\"sq\": \"albanian\",\"sw\": \"swahili\",\"gl\": \"galician\",\"mr\": \"marathi\",\"pa\": \"punjabi\",\"si\": \"sinhala\",\"km\": \"khmer\",\"sn\": \"shona\",\"yo\": \"yoruba\",\"so\": \"somali\",\"af\": \"afrikaans\",\"oc\": \"occitan\",\"ka\": \"georgian\",\"be\": \"belarusian\",\"tg\": \"tajik\",\"sd\": \"sindhi\",\"gu\": \"gujarati\",\"am\": \"amharic\",\"yi\": \"yiddish\",\"lo\": \"lao\",\"uz\": \"uzbek\",\"fo\": \"faroese\",\"ht\": \"haitian creole\",\"ps\": \"pashto\",\"tk\": \"turkmen\",\"nn\": \"nynorsk\",\"mt\": \"maltese\",\"sa\": \"sanskrit\",\"lb\": \"luxembourgish\",\"my\": \"myanmar\",\"bo\": \"tibetan\",\"tl\": \"tagalog\",\"mg\": \"malagasy\",\"as\": \"assamese\",\"tt\": \"tatar\",\"haw\": \"hawaiian\",\"ln\": \"lingala\",\"ha\": \"hausa\",\"ba\": \"bashkir\",\"jw\": \"javanese\",\"su\": \"sundanese\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect language if english model not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \".en\" not in model_name:\n",
    "    # Detect language\n",
    "    audio = whisper.load_audio(mp3_file)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(audio_model.device)\n",
    "    _, probs = audio_model.detect_language(mel)\n",
    "    detected_language = LANGUAGES[max(probs, key=probs.get)]\n",
    "    print(f\"Detected language: {detected_language}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe audio takes about 9 min with gtx1070 to trancsribe 1.5h audio using medium.en\n",
    "\n",
    "if \".en\" not in model_name:\n",
    "    result = audio_model.transcribe(mp3_file, verbose= True, language=detected_language, temperature=0.8)\n",
    "else:\n",
    "    result = audio_model.transcribe(mp3_file, verbose= True, temperature=0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split each sentence to own row and delete .mp3-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(mp3_file)\n",
    "\n",
    "contents = result[\"text\"]\n",
    "\n",
    "# Split text where sentences end\n",
    "contents = contents.replace('\\n', '')\n",
    "contents = contents.replace('? ', '?\\n')\n",
    "contents = contents.replace('. ', '.\\n')\n",
    "contents = contents.replace('! ', '!\\n')\n",
    "\n",
    "# Write/Overwrite contents if any\n",
    "with open(txt_file, 'w') as file:\n",
    "    file.write(contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedd sentences and calulate cosine distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sentences = []\n",
    "with open(txt_file, 'r') as file:\n",
    "        for line in file:\n",
    "                # Remove too short lines\n",
    "                if len(line)>9:\n",
    "                        sentences.append(line)\n",
    "\n",
    "# Define model to be used to be used for text embedding and create similarity matrix\n",
    "text_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = text_model.encode(sentences)\n",
    "similarities = cosine_similarity(embeddings)\n",
    "\n",
    "# Plot the similarity heatmap\n",
    "sns.heatmap(similarities).set_title(f'Cosine similarities matrix {name}')\n",
    "#plt.savefig('{}.png'.format(name), dpi=2000)\n",
    "\n",
    "# Get diagonal and the one next to it for sentence similarity checking\n",
    "diagonals = [similarities.diagonal(), similarities.diagonal(1)+similarities.diagonal(1)[-1]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get diagonals and detect where paragraphs should end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate differences between diagonal and the diagonal next to it\n",
    "difference = [diagonals[0][i]-diagonals[1][i] for i in range(len(diagonals[0])-1)]\n",
    "\n",
    "# Perform n-wide Gaussian smoothing to make paragraphs longer\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "n = 1\n",
    "difference_smoothed = gaussian_filter1d(difference, n)\n",
    "\n",
    "# Detect peaks where sentence difference is largest\n",
    "from scipy.signal import find_peaks\n",
    "peaks, _ = find_peaks(difference_smoothed, distance=5)\n",
    "\n",
    "# Plot peaks\n",
    "plt.clf()\n",
    "plt.plot(difference_smoothed)\n",
    "plt.plot(peaks, difference_smoothed[peaks], \"x\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse final text file using detected paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format text for last step and remove too short sentences.\n",
    "with open(txt_file, 'r') as file:\n",
    "            contents = [l.rstrip(\"\\n\").lstrip() for l in file.readlines() if len(l)>9]\n",
    "\n",
    "# Add paragraph breaks to detected points and write to file\n",
    "text = ''\n",
    "for index, sentence in enumerate(contents):\n",
    "        if index-1 in peaks:\n",
    "                text += \"\\n\\n\"\n",
    "                text += sentence\n",
    "        else:\n",
    "                text += \" \"+sentence\n",
    "\n",
    "with open(txt_file, 'w') as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import OpenAI and define API_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "with open(\"OPENAI_API_KEY\", 'r') as file: # You have to use your own api key here\n",
    "    API_key = file.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting text into chunks so that OpenAi token limit is not exceeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_to_chunks(text):\n",
    "    max_len = 10000\n",
    "    split_points = []\n",
    "    curr_len = 0\n",
    "    for i, char in enumerate(text):\n",
    "        curr_len += 1\n",
    "        if curr_len >= max_len and (char == \".\" or char == \"!\" or char == \"?\"):\n",
    "            split_points.append(i+1)\n",
    "            curr_len = 0\n",
    "    if not split_points:\n",
    "        return [text]\n",
    "    else:\n",
    "        split_texts = []\n",
    "        prev_split = 0\n",
    "        for split in split_points:\n",
    "            split_texts.append(text[prev_split:split])\n",
    "            prev_split = split\n",
    "        split_texts.append(text[prev_split:])\n",
    "        return split_texts\n",
    "    \n",
    "with open(txt_file, 'r') as file:\n",
    "    contents = file.read()\n",
    "contents = contents.replace('\\n', '')\n",
    "\n",
    "chunks = split_text_to_chunks(contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use OpenAI api to get bulletpoints for each text chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = API_key\n",
    "bullet_points =  []\n",
    "\n",
    "for index, text in enumerate(chunks):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"Write a 200 word summray of the provided text. Use your own words and explain all the discussed topics in detail and add extra information if needed.\"},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "    )\n",
    "    bullet_points.append(response.choices[0].message.content)\n",
    "\n",
    "with open(\"Summary_\"+name+\".txt\", 'w') as file:\n",
    "    file.write(' '.join(bullet_points))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40118f5f031a3101398604df892af6a231730f3865c9218da6290b373807c8b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
